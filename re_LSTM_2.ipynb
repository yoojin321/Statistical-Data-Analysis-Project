{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b474c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c7833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466d8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814e2f6",
   "metadata": {},
   "source": [
    "# 개선한 LSTM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb1ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('C:/Users/LG/Desktop/Junior/1학기/통계데이터 분석 공모전/merged_predict2.csv')\n",
    "df['일시'] = pd.to_datetime(df['일시'], format='%m').dt.strftime('%m')\n",
    "df = df.sort_values(by='일시')\n",
    "df = df.fillna(0)\n",
    "df.set_index('일시', inplace=True)\n",
    "\n",
    "X = df[['검색건수', '관외 이동량', '숙박업소 개수', 'sns']]\n",
    "y = df['방문자수']\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82aeb114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터를 LSTM 입력 형식에 맞게 변환\n",
    "def create_sequences(X, y, time_steps=30):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i + time_steps])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 30\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)\n",
    "\n",
    "# 데이터셋 분할\n",
    "split = int(len(X_seq) * 0.8)\n",
    "X_train_seq, X_test_seq = X_seq[:split], X_seq[split:]\n",
    "y_train_seq, y_test_seq = y_seq[:split], y_seq[split:]\n",
    "\n",
    "X_train_rf, X_test_rf = X_scaled[:split], X_scaled[split:]\n",
    "y_train_rf, y_test_rf = y_scaled[:split], y_scaled[split:]\n",
    "\n",
    "# 조기 종료 콜백\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2136e9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엑셀 파일 \"Datasets1.xlsx\"이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 3차원 데이터를 2차원으로 변환\n",
    "X_train_seq_flat = X_train_seq.reshape(-1, X_train_seq.shape[-1])\n",
    "X_test_seq_flat = X_test_seq.reshape(-1, X_test_seq.shape[-1])\n",
    "\n",
    "# 1차원 배열로 변환\n",
    "y_train_seq_flat = y_train_seq.flatten()\n",
    "y_test_seq_flat = y_test_seq.flatten()\n",
    "\n",
    "# DataFrame으로 변환\n",
    "X_train_seq_df = pd.DataFrame(X_train_seq_flat)\n",
    "X_test_seq_df = pd.DataFrame(X_test_seq_flat)\n",
    "y_train_seq_series = pd.Series(y_train_seq_flat)\n",
    "y_test_seq_series = pd.Series(y_test_seq_flat)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "X_train_seq_df.to_csv('X_train_seq.csv', index=False)\n",
    "X_test_seq_df.to_csv('X_test_seq.csv', index=False)\n",
    "y_train_seq_series.to_csv('y_train_seq.csv', index=False, header=True)\n",
    "y_test_seq_series.to_csv('y_test_seq.csv', index=False, header=True)\n",
    "\n",
    "# 저장된 CSV 파일을 엑셀 파일로 합치기\n",
    "csv_files = {\n",
    "    'X_train_seq': 'X_train_seq.csv',\n",
    "    'X_test_seq': 'X_test_seq.csv',\n",
    "    'y_train_seq': 'y_train_seq.csv',\n",
    "    'y_test_seq': 'y_test_seq.csv',\n",
    "}\n",
    "\n",
    "excel_file = 'Datasets1.xlsx'\n",
    "\n",
    "try:\n",
    "    with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:\n",
    "        for sheet_name, csv_file in csv_files.items():\n",
    "            dff = pd.read_csv(csv_file)\n",
    "            dff.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f'엑셀 파일 \"{excel_file}\"이 생성되었습니다.')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f'파일을 찾을 수 없습니다: {csv_file}')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'오류 발생: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e996737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터를 LSTM 입력 형식에 맞게 변환\n",
    "def create_sequences(X, y, time_steps=30):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i + time_steps])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 30\n",
    "\n",
    "# 전체 데이터에 대해 시퀀스 생성\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2faea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 (훈련, 검증, 테스트)\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.15)\n",
    "X_train_seq, y_train_seq = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val_seq, y_val_seq = X_seq[train_size:train_size+val_size], y_seq[train_size:train_size+val_size]\n",
    "X_test_seq, y_test_seq = X_seq[train_size+val_size:], y_seq[train_size+val_size:]\n",
    "\n",
    "# 비시퀀스 모델을 위한 데이터 분할\n",
    "X_train, y_train = X_scaled[time_steps:train_size+time_steps], y_scaled[time_steps:train_size+time_steps]\n",
    "X_val, y_val = X_scaled[train_size+time_steps:train_size+val_size+time_steps], y_scaled[train_size+time_steps:train_size+val_size+time_steps]\n",
    "X_test, y_test = X_scaled[train_size+val_size+time_steps:], y_scaled[train_size+val_size+time_steps:]\n",
    "\n",
    "# 시계열 교차검증 설정\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf754c1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LG\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0391 - val_loss: 0.0256\n",
      "Epoch 2/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0244 - val_loss: 0.0256\n",
      "Epoch 3/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0256 - val_loss: 0.0246\n",
      "Epoch 4/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0237 - val_loss: 0.0250\n",
      "Epoch 5/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0233 - val_loss: 0.0242\n",
      "Epoch 6/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0234 - val_loss: 0.0239\n",
      "Epoch 7/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0242 - val_loss: 0.0240\n",
      "Epoch 8/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0228 - val_loss: 0.0242\n",
      "Epoch 9/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0248 - val_loss: 0.0243\n",
      "Epoch 10/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0229 - val_loss: 0.0237\n",
      "Epoch 11/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0259 - val_loss: 0.0241\n",
      "Epoch 12/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0240 - val_loss: 0.0238\n",
      "Epoch 13/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0228 - val_loss: 0.0236\n",
      "Epoch 14/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0236 - val_loss: 0.0244\n",
      "Epoch 15/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0235 - val_loss: 0.0247\n",
      "Epoch 16/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0238 - val_loss: 0.0236\n",
      "Epoch 17/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0258 - val_loss: 0.0237\n",
      "Epoch 18/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0223 - val_loss: 0.0240\n",
      "Epoch 19/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0242 - val_loss: 0.0237\n",
      "Epoch 20/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0232 - val_loss: 0.0236\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0219 \n",
      "Epoch 1/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0290 - val_loss: 0.0247\n",
      "Epoch 2/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0275 - val_loss: 0.0244\n",
      "Epoch 3/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0251 - val_loss: 0.0272\n",
      "Epoch 4/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0249 - val_loss: 0.0244\n",
      "Epoch 5/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0247 - val_loss: 0.0237\n",
      "Epoch 6/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0272 - val_loss: 0.0243\n",
      "Epoch 7/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0261 - val_loss: 0.0239\n",
      "Epoch 8/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0234 - val_loss: 0.0250\n",
      "Epoch 9/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0247 - val_loss: 0.0245\n",
      "Epoch 10/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0217 - val_loss: 0.0236\n",
      "Epoch 11/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0235 - val_loss: 0.0254\n",
      "Epoch 12/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0231 - val_loss: 0.0236\n",
      "Epoch 13/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0238 - val_loss: 0.0248\n",
      "Epoch 14/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0227 - val_loss: 0.0239\n",
      "Epoch 15/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0258 - val_loss: 0.0235\n",
      "Epoch 16/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0237 - val_loss: 0.0241\n",
      "Epoch 17/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0246 - val_loss: 0.0237\n",
      "Epoch 18/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0216 - val_loss: 0.0259\n",
      "Epoch 19/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0248 - val_loss: 0.0235\n",
      "Epoch 20/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0214 - val_loss: 0.0254\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 \n",
      "Epoch 1/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0409 - val_loss: 0.0257\n",
      "Epoch 2/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0268 - val_loss: 0.0249\n",
      "Epoch 3/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0273 - val_loss: 0.0244\n",
      "Epoch 4/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0260 - val_loss: 0.0245\n",
      "Epoch 5/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0235 - val_loss: 0.0251\n",
      "Epoch 6/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0242 - val_loss: 0.0239\n",
      "Epoch 7/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0253 - val_loss: 0.0240\n",
      "Epoch 8/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0231 - val_loss: 0.0240\n",
      "Epoch 9/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0250 - val_loss: 0.0239\n",
      "Epoch 10/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0236 - val_loss: 0.0240\n",
      "Epoch 11/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0240 - val_loss: 0.0236\n",
      "Epoch 12/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0256 - val_loss: 0.0237\n",
      "Epoch 13/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0238 - val_loss: 0.0235\n",
      "Epoch 14/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0236 - val_loss: 0.0240\n",
      "Epoch 15/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0230 - val_loss: 0.0236\n",
      "Epoch 16/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0234 - val_loss: 0.0234\n",
      "Epoch 17/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0235 - val_loss: 0.0239\n",
      "Epoch 18/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0251 - val_loss: 0.0235\n",
      "Epoch 19/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0228 - val_loss: 0.0244\n",
      "Epoch 20/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0240 - val_loss: 0.0236\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0220 \n",
      "Epoch 1/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0317 - val_loss: 0.0359\n",
      "Epoch 2/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0260 - val_loss: 0.0247\n",
      "Epoch 3/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0245 - val_loss: 0.0254\n",
      "Epoch 4/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0233 - val_loss: 0.0261\n",
      "Epoch 5/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0244 - val_loss: 0.0241\n",
      "Epoch 6/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0261 - val_loss: 0.0238\n",
      "Epoch 7/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0223 - val_loss: 0.0243\n",
      "Epoch 8/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0254 - val_loss: 0.0237\n",
      "Epoch 9/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0279 - val_loss: 0.0242\n",
      "Epoch 10/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0242 - val_loss: 0.0238\n",
      "Epoch 11/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0233 - val_loss: 0.0245\n",
      "Epoch 12/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0268 - val_loss: 0.0257\n",
      "Epoch 13/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0230 - val_loss: 0.0243\n",
      "Epoch 14/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0240 - val_loss: 0.0242\n",
      "Epoch 15/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0247 - val_loss: 0.0235\n",
      "Epoch 16/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 17/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0230 - val_loss: 0.0235\n",
      "Epoch 18/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0251 - val_loss: 0.0236\n",
      "Epoch 19/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0241 - val_loss: 0.0235\n",
      "Epoch 20/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0225 - val_loss: 0.0248\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0238 \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "{'Best Model': <Sequential name=sequential, built=True>, 'Best Parameters': {'units': 50, 'optimizer': 'adam'}, 'History': <keras.src.callbacks.history.History object at 0x000001B8E67E9B50>, 'MSE': 9514580242101.494, 'MAE': 2313874.744755245, 'NMAE': 0.5448238306134002, 'R2': 0.165122391902781, 'Accuracy': 16.5122391902781}\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# import numpy as np\n",
    "\n",
    "# # create_and_fit_model 함수 정의\n",
    "# def create_and_fit_model(X_train, y_train, X_val, y_val, units, optimizer):\n",
    "#     model = Sequential([\n",
    "#         LSTM(units, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "#         Dense(1)\n",
    "#     ])\n",
    "#     model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "#     history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=50)\n",
    "#     return model, history\n",
    "\n",
    "# # 그리드 서치에 사용될 파라미터\n",
    "# lstm_params = {'units': [50, 100], 'optimizer': ['adam', 'rmsprop']}\n",
    "\n",
    "# # 모델 딕셔너리 설정\n",
    "# models = {\n",
    "#     'LSTM': (None, lstm_params)  # 모델 생성은 함수 내에서 처리\n",
    "# }\n",
    "\n",
    "# results = {}\n",
    "# best_score = float('inf')\n",
    "# best_params = None\n",
    "# best_model = None\n",
    "\n",
    "# # 그리드 서치 수행\n",
    "# for units in lstm_params['units']:\n",
    "#     for optimizer in lstm_params['optimizer']:\n",
    "#         model, history = create_and_fit_model(X_train_seq, y_train_seq, X_val_seq, y_val_seq, units=units, optimizer=optimizer)\n",
    "#         score = model.evaluate(X_val_seq, y_val_seq)\n",
    "#         if score < best_score:\n",
    "#             best_score = score\n",
    "#             best_params = {'units': units, 'optimizer': optimizer}\n",
    "#             best_model = model\n",
    "\n",
    "# # 결과 저장\n",
    "# results['LSTM'] = {\n",
    "#     'Best Model': best_model, \n",
    "#     'Best Parameters': best_params, \n",
    "#     'History': history\n",
    "# }\n",
    "\n",
    "# # 예측 및 역스케일링\n",
    "# y_pred = best_model.predict(X_test_seq)\n",
    "# y_true = y_test_seq\n",
    "# y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 1))\n",
    "# y_true = scaler_y.inverse_transform(y_true.reshape(-1, 1))\n",
    "\n",
    "# # 성능 지표 계산\n",
    "# mse = mean_squared_error(y_true, y_pred)\n",
    "# mae = mean_absolute_error(y_true, y_pred)\n",
    "# nmae = mae / np.mean(np.abs(y_true))\n",
    "# r2 = r2_score(y_true, y_pred)\n",
    "# accuracy = r2 * 100\n",
    "\n",
    "# # 성능 지표 결과 업데이트\n",
    "# results['LSTM'].update({\n",
    "#     'MSE': mse,\n",
    "#     'MAE': mae,\n",
    "#     'NMAE': nmae,\n",
    "#     'R2': r2,\n",
    "#     'Accuracy': accuracy\n",
    "# })\n",
    "\n",
    "# print(results['LSTM'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2547e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 생성 및 훈련 함수\n",
    "def create_and_fit_model(X_train, y_train, X_val, y_val, units=50, optimizer='adam', epochs=100, batch_size=32):\n",
    "    model = Sequential([\n",
    "        LSTM(units, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                        validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a24c76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 서치를 위한 파라미터 설정\n",
    "lstm_params = {\n",
    "    'units': [30, 50, 70],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba103cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 평가 함수\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    nmae = calculate_nmae(y_true, y_pred, S)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, mae, nmae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de6aab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LSTM': (create_and_fit_model, lstm_params)\n",
    "}\n",
    "\n",
    "# 결과 저장을 위한 딕셔너리\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45061383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search for LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LG\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LSTM with units=30, optimizer=adam, score=0.023543961346149445\n",
      "Testing LSTM with units=30, optimizer=rmsprop, score=0.023534566164016724\n",
      "Testing LSTM with units=50, optimizer=adam, score=0.02354712225496769\n",
      "Testing LSTM with units=50, optimizer=rmsprop, score=0.023670662194490433\n",
      "Testing LSTM with units=70, optimizer=adam, score=0.023693736642599106\n",
      "Testing LSTM with units=70, optimizer=rmsprop, score=0.02351974882185459\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Results for LSTM: MSE=9486957705864.871, MAE=2380572.9082167833, R2=0.167546191628676, Accuracy=16.754619162867602%\n"
     ]
    }
   ],
   "source": [
    "for name, (model_func, params) in models.items():\n",
    "    print(f\"Performing grid search for {name}...\")\n",
    "\n",
    "    if name in ['LSTM']:\n",
    "        best_score = float('inf')\n",
    "        best_params = None\n",
    "        best_model = None\n",
    "        best_history = None\n",
    "\n",
    "        for units in params['units']:\n",
    "            for optimizer in params['optimizer']:\n",
    "                model, history = model_func(X_train_seq, y_train_seq, X_val_seq, y_val_seq,\n",
    "                                            units=units, optimizer=optimizer)\n",
    "                score = model.evaluate(X_val_seq, y_val_seq, verbose=0)\n",
    "                print(f\"Testing {name} with units={units}, optimizer={optimizer}, score={score}\")\n",
    "\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_params = {'units': units, 'optimizer': optimizer}\n",
    "                    best_model = model\n",
    "                    best_history = history\n",
    "\n",
    "        results[name] = {'Best Model': best_model, 'Best Parameters': best_params, 'History': best_history}\n",
    "    else:\n",
    "        # Adjust as needed for other model types if added later\n",
    "        pass\n",
    "\n",
    "    # Evaluate the best model\n",
    "    y_pred = best_model.predict(X_test_seq)\n",
    "    y_true = y_test_seq\n",
    "\n",
    "    # Inverse transform to original scale\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    y_true = scaler_y.inverse_transform(y_true)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    accuracy = r2 * 100\n",
    "\n",
    "    results[name].update({\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "    print(f\"Results for {name}: MSE={mse}, MAE={mae}, R2={r2}, Accuracy={accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb88a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
